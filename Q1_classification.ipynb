{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(fileName, inputcols, outputcol):\n",
    "    dataset = pd.read_table(fileName, header = 0, sep = \",\", encoding = \"unicode_escape\")\n",
    "    data = dataset[inputcols]\n",
    "    target = dataset[outputcol]\n",
    "\n",
    "    trainingX, testX, trainingY, testY = train_test_split(data, target, test_size = 0.33, random_state = 43)\n",
    "    # normalizing the data and converting to numpy arrays\n",
    "    testX = np.array(testX/testX.abs().max())\n",
    "    testY = np.array(testY/testY.abs().max())\n",
    "    trainingX = np.array(trainingX/trainingX.abs().max())\n",
    "    trainingY = np.array(trainingY/trainingY.abs().max())\n",
    "    \n",
    "    return trainingX, testX, trainingY, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSigmoid(num):\n",
    "    return 1/(1 + np.exp(-num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwardPropagation(sigmoidVal, netW, hiddenNeurons, outputNeurons, learningRate):\n",
    "    delta = learningRate * netW.dot(np.resize(sigmoidVal, (outputNeurons, hiddenNeurons)))\n",
    "    delta = np.transpose(np.resize(delta, (outputNeurons, hiddenNeurons)))\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_model(trainingX, trainingY, inputNeurons, hiddenNeurons, outputNeurons, learningRate, epochs):\n",
    "  \n",
    "    classifier = None\n",
    "    #Your custom implementation of neural networks will go here.\n",
    "    # assigning random weights to input-hidden and hidden-output\n",
    "    hiddenW = np.random.rand(inputNeurons, hiddenNeurons) \n",
    "    outputW = np.random.rand(hiddenNeurons, outputNeurons)\n",
    "    # converting trainingX and trainingY to numpy arrays\n",
    "    trainingX_arr = np.array(trainingX)\n",
    "    trainingY_arr = np.array(trainingY)\n",
    "    # print(trainingX_arr) \n",
    "    # print(trainingY_arr)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        index = 0\n",
    "        for val in trainingX_arr:\n",
    "            # print(val)\n",
    "        \n",
    "            # Forward propagation\n",
    "            # calculating biases\n",
    "            hiddenBias = np.random.randn((hiddenNeurons)) * 0.01\n",
    "            outputBias = np.random.randn((outputNeurons)) * 0.01\n",
    "            # print(bias)\n",
    "           \n",
    "            # hidden layer forward propagation\n",
    "            totalHiddenW = np.dot(val, hiddenW) + hiddenBias\n",
    "            # print(totalHiddenW)\n",
    "            hiddenSigmoidVal = getSigmoid(totalHiddenW)\n",
    "            # print(hiddenSigmoidVal)\n",
    "\n",
    "            # output layer forward propagation\n",
    "            totalOutputW = np.dot(hiddenSigmoidVal, outputW) + outputBias\n",
    "            outputSigmoidVal = getSigmoid(totalOutputW)\n",
    "            \n",
    "            # Backward propagation\n",
    "            # output layer errors     \n",
    "            outputError = (trainingY_arr[index] - outputSigmoidVal)\n",
    "            outputNet = outputSigmoidVal * (1 - outputSigmoidVal) * outputError\n",
    "            # print(hiddenList)\n",
    "        \n",
    "            # calculating the change for output neurons\n",
    "            outputDelta = backwardPropagation(hiddenSigmoidVal, outputNet, hiddenNeurons, outputNeurons, learningRate)\n",
    "            # adjusting the hidden-output weights\n",
    "            outputW +=  outputDelta\n",
    "            # print(outputW) \n",
    "\n",
    "\n",
    "            # hidden layer errors\n",
    "            hiddenError = np.dot(outputW, outputNet)\n",
    "            hiddenNet = hiddenSigmoidVal * (1 - hiddenSigmoidVal) * hiddenError\n",
    "            \n",
    "            # calculating the change for hidden neurons\n",
    "            hiddenDelta = backwardPropagation(val, hiddenNet, 3, hiddenNeurons, learningRate)\n",
    "            # adjusting the input-hidden weights\n",
    "            hiddenW += hiddenDelta\n",
    "            index += 1\n",
    "        \n",
    "    classifier = {\"hiddenWeights\": hiddenW ,\"outputWeights\" : outputW}\n",
    "    # print(classifier)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(val, classifier):\n",
    "    hiddenW, outputW = classifier['hiddenWeights'], classifier['outputWeights']\n",
    "    hiddenVal = np.dot(val, hiddenW)\n",
    "    hiddenSigmoidVal = getSigmoid(hiddenVal)\n",
    "\n",
    "    outputVal = np.dot(hiddenSigmoidVal, outputW)\n",
    "    output = getSigmoid(outputVal)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(classifier, testdata):\n",
    "    \n",
    "    predicted_val=[]\n",
    "    #Your code to make predictions on test data using the learned model will go here\n",
    "\n",
    "    for x in testdata:\n",
    "        output = predict(x, classifier)[0]\n",
    "        predicted_val.append(output)\n",
    "    \n",
    "    # print(predicted_val)\n",
    "    return predicted_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeError(actual_class, predicted_class):\n",
    "        \n",
    "    MSE = -1    \n",
    "    #Your code to compute MSE will go here\n",
    "    diff = np.square(actual_class - predicted_class)\n",
    "    MSE = np.sum(diff)/len(predicted_class)\n",
    "    \n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data.....\n",
      "Learning model.....\n",
      "Classifying test data......\n",
      "Evaluating results.....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02602350263009224"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, target = [\"X1\",\"X2\",\"X3\"], \"Y\"\n",
    "\n",
    "print(\"Loading data.....\")\n",
    "trainingX,testX,trainingY,testY = load_file(\"kseindex.csv\", features, target)\n",
    "# print(testX)\n",
    "print(\"Learning model.....\")\n",
    "model = learn_model(trainingX,trainingY,3,4,1,0.8,10)\n",
    "\n",
    "print(\"Classifying test data......\")\n",
    "predictedY = classify(model, testX)\n",
    "\n",
    "print(\"Evaluating results.....\")\n",
    "computeError(testY, predictedY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ec81b5741290afa0545a4f5062f07e05d97808451c29876a22c76fe0d3ca11f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
